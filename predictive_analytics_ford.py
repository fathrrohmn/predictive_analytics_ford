# -*- coding: utf-8 -*-
"""predictive_analytics_ford.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FYFqvTIXrLJ93ungkkDrMVc3EM6iePlN

# **Proyek Akhir: Predictive Analysis**

---

# Data Diri

Nama: Moh Fatchurrohman  
E-mail: fathrohman77@gmail.com

# **1. Import Library**

*Library* [`os`](https://docs.python.org/3/library/os.html) untuk memproses *function* dari *operating system*. `os.environ` untuk membaca *username* dan *key* [Kaggle](https://kaggle.com).

*Library* [`pandas`](https://pandas.pydata.org) untuk melakukan pemrosesan, analisis dan manipulasi data.

*Library* [`tensorflow`](https://www.tensorflow.org) untuk melakukan pelatihan *machine learning* dan *neural networks*.

*Library* [`sklearn`](https://scikit-learn.org) untuk melakukan pemrosesan *machine learning* dan *data analysis*.

*Library* [`seaborn`](https://seaborn.pydata.org) untuk membuat visualisasi data yang berbasis `matplotlib`.

*Library* [`matplotlib`](https://matplotlib.org/) untuk melakukan visualisasi menggunakan *plotting*.
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

"""# **2. Data Loading**

## 2.1 Environment and Kaggle Credential

**Mengatur *environment*** `operating system` [Colab](https://colab.research.google.com) dengan variabel `KAGGLE_USERNAME` dan variabel `KAGGLE_KEY` untuk menghubungkan platform [Kaggle](https://kaggle.com/) menggunakan [Kaggle's Beta API](https://www.kaggle.com/docs/api) Token.
"""

# Username dan key Kaggle API
os.environ['KAGGLE_USERNAME'] = 'mohfatchurrohman'
os.environ['KAGGLE_KEY']      = '5ca599b3bbb5c61c18cdc5f0f9c31a00'

"""## 2.2 Dataset Download

**Mengunduh (*download*) *dataset*** dari Kaggle dengan nama *file* *dataset*, yaitu `ford.csv`. *Dataset* yang digunakan dalam proyek ini adalah *dataset* [Used Car](https://www.kaggle.com/datasets/adityadesai13/used-car-dataset-ford-and-mercedes?select=ford.csv) yang berupa berkas `.csv` ([Comma-separated Values](https://en.wikipedia.org/wiki/Comma-separated_values)).
"""

# Download dataset dari Kaggle
!kaggle datasets download -d adityadesai13/used-car-dataset-ford-and-mercedes -f ford.csv

"""**Menampilkan isi *dataset*** menggunakan *library* [Pandas](https://pandas.pydata.org/) dengan mengubah format CSV menjadi *dataframe*."""

ford = pd.read_csv('ford.csv')
ford

"""Dari *dataframe* di atas dapat dilihat bahwa terdapat 17965 baris data dengan atribut sebanyak 9 kolom.
1.   `model` : Model mobil Ford
2.   `year` : Tahun registrasi
3.   `price` : Harga
4.   `transmission` : Transmisi
5.   `mileage` : Jarak yang tempuh
6.   `fuelType` : Jenis bahan bakar
7.   `tax` : Pajak jalan
8.   `mpg` : Mil per galon
9.   `engineSize` : Ukuran mesin (dalam liter)

## 2.3 Exploratory Data Analysis (EDA)

*Explanatory Data Analysis* (EDA) adalah suatu proses investigasi awal pada data untuk melakukan analisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data dengan menggunakan bantuan statistik dan representasi grafis atau visualisasi.

**2.3.1 Deskripsi Variabel**

Melakukan pengecekan informasi dari *dataframe* `ford` seperti, jumlah kolom, nama kolom, jumlah data setiap kolom, dan tipe data pada kolom.
"""

ford.info()

"""Terdapat dua (2) atribut dengan tipe data `float64`, empat (4) atribut dengan tipe data `int64`, dan tiga (3) atribut dengan tipe data `object`.

**2.3.2 Deskripsi Statistik**
"""

ford.describe()

"""Melihat deskripsi statistik dari *dataframe* `ford` yaitu,
1.   `count` : Jumlah data
2.   `mean` : Rata-rata
3.   `std` : Standar deviasi/simpangan baku
4.   `min` : Nilai minimum
5.   `25%` : Kuartil bawah/Q1
6.   `50%` : Kuartil tengah/Q2/median
7.   `75%` : Kuartil atas/Q3
8.   `max` : Nilai maksimum

**2.3.3 Menangani Missing Value**

Melakukan pengecekan apakah pada *dataframe* `ford` terdapat nilai 0.
"""

tax = (ford.tax == 0).sum()
engineSize = (ford.engineSize == 0).sum()

print("Nilai 0 di kolom tax ada: ", tax)
print("Nilai 0 di kolom engineSize ada: ", engineSize)

"""Pada *dataframe* `ford` ternyata ditemukan adanya nilai 0 di kolom `tax` ada 2153 dan di kolom `engineSize ` ada 51.  """

ford.loc[(ford['tax']==0)]

# Drop baris dengan nilai 'tax' dan 'engineSize' = 0
ford = ford.loc[(ford[['tax','engineSize']]!=0).all(axis=1)]

# Cek ukuran data untuk memastikan baris sudah di-drop
ford.shape

ford.describe()

"""**2.3.3 Menangani Outliers**

Melakukan pengecekan pada *dataframe* `ford` terdapat data *outliers* atau sampel data yang nilainya berada sangat jauh dari cakupan umum data utama yang dapat merusak hasil analisis data. Pengecekan dilakukan dengan cara visualisasi data menggunakan [`boxplot`](https://seaborn.pydata.org/generated/seaborn.boxplot.html) dengan bantuan *library* [`seaborn`](https://seaborn.pydata.org/).
"""

# Mendeteksi outliers
fig, axes = plt.subplots(2, 3, figsize=(14, 7))

sns.boxplot(ax=axes[0, 0], x=ford.year)
sns.boxplot(ax=axes[0, 1], x=ford.price)
sns.boxplot(ax=axes[0, 2], x=ford.mileage)

sns.boxplot(ax=axes[1, 0], x=ford.tax)
sns.boxplot(ax=axes[1, 1], x=ford.mpg)
sns.boxplot(ax=axes[1, 2], x=ford.engineSize)

"""Dapat dilihat pada diagram boxplot (diagram kotak garis) di atas, terdapat beberapa fitur numerik yang memiliki *outliers* seperti, `year`, `price`, `mileage`, `tax`, `mpg`, dan `engineSize`.

Untuk mengatasi *outliers*, dilakukan pendekatan menggunakan metode IQR (*Inter Quartile Range*).  

$IQR=Q3-Q1$  

Kemudian membuat batas bawah dan batas atas untuk mencakupi *outliers*.  

$batasBawah=Q1-1.5*IQR$  
$batasAtas=Q3-1.5*IQR$
"""

# Mengatasi outliers
numeric_columns = ['year', 'price', 'mileage', 'tax', 'mpg', 'engineSize']
Q1 = ford[numeric_columns].quantile(0.25)
Q3 = ford[numeric_columns].quantile(0.75)
IQR=Q3-Q1
ford=ford[~((ford[numeric_columns]<(Q1-1.5*IQR))|(ford[numeric_columns]>(Q3+1.5*IQR))).any(axis=1)]

# Cek ukuran dataset setelah kita drop outliers
ford.shape

"""Sehingga diperoleh data yang telah dibersihkan sebanyak 8401 sampel.

Melakukan pengecekan kembali terhadap *outliers* dengan menggunakan visualisasi boxplot.
"""

# Mendeteksi outliers
fig, axes = plt.subplots(2, 3, figsize=(14, 7))

sns.boxplot(ax=axes[0, 0], x=ford.year)
sns.boxplot(ax=axes[0, 1], x=ford.price)
sns.boxplot(ax=axes[0, 2], x=ford.mileage)

sns.boxplot(ax=axes[1, 0], x=ford.tax)
sns.boxplot(ax=axes[1, 1], x=ford.mpg)
sns.boxplot(ax=axes[1, 2], x=ford.engineSize)

"""Seletah dilakukan pembersihan *outliers* menggunakan metode IQR (*Inter Quartile Range*), dapat dilihat bahwa *outliers* telah berkurang pada boxplot di atas. Meskipun *outliers* masih ada pada fitur `year`, `mileage`, dan `engineSize`, tetapi masih dalam batas aman.

**2.3.4 Univariate Analysis**

Melakukan proses analisis data *univariate* pada fitur-fitur numerik.
"""

numerical_features = ['price', 'mileage', 'tax', 'mpg', 'engineSize']
categorical_features = ['model', 'year', 'transmission', 'fuelType']

# Categorical Features - Fitur Model
feature = categorical_features[0]
count = ford[feature].value_counts()
percent = 100*ford[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Dari data tabel dan histogram di atas diperoleh informasi, yaitu: model mobil yang paling banyak terjual adalah Model `Fiesta` dengan jumlah 3122 atau sebesar 37.2%"""

# Categorical Features - Fitur Year
feature = categorical_features[1]
count = ford[feature].value_counts()
percent = 100*ford[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Dari data tabel dan histogram di atas diperoleh informasi, yaitu: yang paling banyak terjual adalah mobil dengan tahun registrasi `2018` dengan jumlah 3228 atau sebesar 38.4%"""

# Categorical Features - Fitur Transmission
feature = categorical_features[2]
count = ford[feature].value_counts()
percent = 100*ford[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Dari data tabel dan histogram di atas diperoleh informasi, yaitu: transmisi mobil yang paling banyak terjual adalah transmisi `Manual` dengan jumlah 7290 atau sebesar 86.8%"""

# Categorical Features - Fitur Fuel Type
feature = categorical_features[3]
count = ford[feature].value_counts()
percent = 100*ford[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Dari data tabel dan histogram di atas diperoleh informasi, yaitu: jenis bahan bakar dari mobil yang paling banyak terjual adalah jenis `Petrol` dengan jumlah 6243 atau sebesar 74.3%"""

# Numerical Features
ford.hist(bins=50, figsize=(20,15))
plt.show()

"""Dari data histogram di atas diperoleh informasi, yaitu:
1.   Penjualan mobil Ford paling banyak pada tahun 2018.
2.   Harga penjualan mobil Ford sebagian besar berada pada rentang 9500 sampai 18000, dan paling tinggi di harga sekitar 11000.
3.   Jarak tempuh pada mobil Ford yang terjual sebagian besar berada pada rentang 0 mile hingga 18000 mile, dan jarak tempuh yang paling panjang berada pada sekitar 10000 mile.
4.   Konsumsi bahan bakar (mil per galon) dari mobil Ford yang terjual sebagian besar pada rentang 55 mpg hingga 68 mpg, dan konsumsi bahan bakar dari mobil Ford paling banyak hingga 68 mpg.
5.   Ukuran mesin yang paling banyak adalah 1.0.
6.   Pendapatan pajak yang paling besar adalah 145.

**2.3.5 Multivariate Analysis**

Melakukan visualisasi distribusi data pada fitur-fitur numerik dari *dataframe* `ford`. Visualisasi dilakukan dengan bantuan *library* `seaborn` `pairplot` menggunakan parameter `diag_kind`, yaitu `kde`, untuk melihat perkiraan distribusi probabilitas antar fitur numerik.
"""

# Categorical Features
cat_features = ford.select_dtypes(include='object').columns.to_list()

for col in cat_features:
  sns.catplot(x=col, y="price", kind="bar", dodge=False, height = 4, aspect = 3,  data=ford, palette="Set3")
  plt.title("Rata-rata 'price' Relatif terhadap - {}".format(col))

# Numerical Features
# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(ford, diag_kind = 'kde')

"""**2.3.6 Correlation Matrix menggunakan Heatmap**

Melakukan pengecekan korelasi antar fitur numerik dengan menggunakan visualisasi diagram *heatmap* *correlation matrix*.
"""

# Mengevaluasi skor korelasi
plt.figure(figsize=(10, 8))
correlation_matrix = ford[numerical_features].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Dapat dilihat pada diagram *heatmap* di atas memiliki *range* atau rentang angka dari 1.0 hingga 0.4 dengan keterangan sebagai berikut,
*   Jika semakin mendekati 1, maka korelasi antar fitur numerik semakin kuat bernilai positif.
*   Jika semakin mendekati 0, maka korelasi antar fitur numerik semakin rendah.
*   Jika semakin mendekati -1, maka korelasi antar fitur numerik semakin kuat bernilai negatif.

Jika korelasi bernilai positif, berarti nilai kedua fitur numerik cenderung meningkat bersama-sama.

Jika korelasi bernilai negatif, berarti nilai salah satu fitur numerik cenderung meningkat ketika nilai fitur numerik yang lain menurun.

**2.3.6 Analisis Korelasi Antar Fitur**

Fitur `price` memiliki korelasi yang cukup kuat dengan fitur `mileage`, `mpg` dan `engineSize`.

Sehingga, fitur `tax` tidak memiliki korelasi dengan fitur `price`. Dengan begitu, dapat dilakukan *drop* (menghapus) fitur-fitur tersebut.
"""

# Drop korelasi yang sangat kecil
ford.drop(['tax'], inplace=True, axis=1)
ford.head()

"""## 2.4 Data Preparation

**2.4.1 Encoding Fitur Kategori**
"""

from sklearn.preprocessing import  OneHotEncoder
ford = pd.concat([ford, pd.get_dummies(ford['model'], prefix='model')],axis=1)
ford = pd.concat([ford, pd.get_dummies(ford['year'], prefix='year')],axis=1)
ford = pd.concat([ford, pd.get_dummies(ford['transmission'], prefix='transmission')],axis=1)
ford = pd.concat([ford, pd.get_dummies(ford['fuelType'], prefix='fuelType')],axis=1)
ford.drop(['model','year','transmission','fuelType'], axis=1, inplace=True)
ford.head()

"""**2.4.2 Train-Test-Split**

Melakukan *define* atau mendefinisikan variabel `X` yang berisi fitur-fitur untuk memprediksi penggunaan daya (*power consumption*) dengan mengecualikan fitur yang tidak diperlukan, serta variabel `y` yang merupakan fitur target atau nilai yang akan diprediksi.

Melakukan pembagian *dataset* (*split data*) dengan menggunakan `train_test_split` menjadi data latih (*training*) dan data uji (*testing*). Lalu menampilkan total *dataset* secara keseluruhan, total data latih (*training*), dan total data uji (*testing*).
"""

from sklearn.model_selection import train_test_split

X = ford.drop(["price"],axis =1)
y = ford["price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

# Cek jumlah sampel
print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""**2.4.3 Standarisasi pada Fitur Numerik**

Melakukan standarisasi nilai pada fitur numerik dengan menggunakan `StandardScaler` dari *library* `scikit-learn`. Proses standarisasi ini bertujuan untuk mencegah terjadinya penyimpangan nilai data yang cukup besar.
"""

from sklearn.preprocessing import StandardScaler

numerical_features = ['engineSize']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

# Cek nilai mean dan standar deviasi
X_train[numerical_features].describe().round(4)

"""`StandardScaler` akan melakukan proses standarisasi fitur dengan mengurangkan nilai rata-rata (`mean`) lalu membaginya dengan standar deviasi/simpangan baku (`std`) untuk menggeser distribusi nilai. Proses standarisasi akan menghasilakn distribusi dengan nilai rata-rata (`mean`) menjadi 0 dan nilai standar deviasi/simpangan baku (`std`) menjadi 1.

## 2.5 Model Development

**2.5.1 Model Preparation**

Mempersiapkan *dataframe* untuk melakukan analisis model dengan parameter `index`, yaitu `train_mse` dan `test_mse`, serta parameter `columns` yang merupakan algoritma yang akan digunakan untuk melakukan prediksi, yaitu algoritma K-Nearest Neighbor (KNN), Random Forest, dan Adaptive Boosting (AdaBoost).
"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""**2.5.2 Model K-Nearest Neighbor (KNN)**

Algoritma K-Nearest Neighbor (KNN) akan menggunakan metode kemiripan dari data uji (*testing*) dan data latih (*training*) dengan mencari kesamaan pada fitur-fiturnya. K-Nearest Neighbor bekerja dengan membandingkan jarak satu sampel ke sampel pelatihan lain berdasarkan sejumlah k-tetangga terdekat (k = nilai atau angka positif).
"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""**2.5.3 Model Random Forest**

Algoritma Random Forest merupakan algoritma *supervised learning* yang termasuk pada golongan *ensemble* (*group*) *learning*. Oleh karena itu, algoritma Random Forest terdiri dari beberapa model yang akan bekerja bersama-sama secara independen, dan prediksi dari setiap model ensemble akan digabungkan untuk membuat hasil prediksi akhir.
"""

# Impor library yang dibutuhkan
from sklearn.ensemble import RandomForestRegressor

# Buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""**2.5.4 Model Boosting Algorithm**

Algoritma Adaptive Boosting (AdaBoost) merupakan algoritma yang melatih model secara berurutan dan dalam proses iteratif (berulang). Data latih (training) akan memiliki *weight* atau bobot yang sama, kemudian model akan melakukan pemeriksaan atau observasi. Bobot yang lebih tinggi kemudian akan dimasukkan ke dalam model yang salah sehingga akan lanjut ke tahap selanjutnya. Proses iteratif tersebut akan berlanjut hingga model mencapai akurasi yang diinginkan.
"""

from sklearn.ensemble import AdaBoostRegressor

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""## 2.6 Evaluasi Model

Melakukan standarisasi atau *scaling* pada fitur numerik data uji (*testing*) sehingga rata-rata (*mean*) bernilai 0, dan varians bernilai 1.
"""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""Melakukan evaluasi dari ketiga model, yaitu algoritma K-Nearest Neighbor, Random Forest, dan Adaptive Boosting (AdaBoost) untuk masing-masing data latih (*training*) dan data uji (*testing*) dengan melihat tingkat *error*-nya menggunakan Mean Squared Error (MSE)."""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

"""Melakukan visualisasi data *error* setiap model dengan algoritma K-Nearest Neighbor, Random Forest, dan Adaptive Boosting (AdaBoost) untuk masing-masing data latih (*training*) dan data uji (*testing*) dengan menggunakan plot *bar chart*."""

# Plot metrik
fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Dari visualisasi diagram di atas dapat disimpulkan bahwa,
1.   Model dengan algoritma Random Forest memberikan nilai *error* yang paling kecil, yaitu sebesar 498.5 pada *training error*, dan 1542.5 pada *testing error*.
2.   Model dengan algoritma Adaptive Boosting memiliki tingkat *error* yang sedang di antara dua algoritma lainnya.
3.   Model dengan algoritma K-Nearest Neighbor mengalami *error* yang paling beser dengan nilai *training error* sebesar 9976.8, dan nilai *testing error* sebesar 13319.4.

Melakukan pengujian prediksi dengan menggunakan beberapa nilai harga (*price*) dari data uji (*testing*)
"""

# Buat prediksi
prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Dapat dilihat prediksi pada model dengan algoritma Random Forest memberikan hasil yang paling mendekati dengan nilai `y_true` jika dibandingkan dengan algoritma model yang lainnya.

Nilai `y_true` sebesar **9750** dan nilai prediksi `Random Forest` sebesar **10032.9**.

Kesimpulannya adalah model yang digunakan untuk melakukan prediksi harga mobil bekas produsen mobil Ford (*Used Car*) menghasilkan **tingkat *error* yang paling rendah** dengan menggunakan **algoritma Random Forest** pada model yang telah dibangun.
"""